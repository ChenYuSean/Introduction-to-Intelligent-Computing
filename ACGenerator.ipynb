{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "# Torch Module\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.utils import save_image\n",
    "# PIL Module\n",
    "from PIL import Image, ImageFile\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from ACGAN import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make A Dictionary For Car\n",
    "\n",
    "{\"name.jpg\" : (brand,year,color)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Audi Data\n",
    "img_folder = os.path.join('.', 'confirmed_fronts')\n",
    "brand_folder = os.listdir(img_folder)\n",
    "image_path = []\n",
    "search_path = os.path.join(img_folder,\"Audi\",\"*\",\"*.jpg\")\n",
    "image_path += glob.glob(search_path) \n",
    "image_name = list(map(os.path.basename,image_path))\n",
    "#print(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the label element into list\n",
    "brand_list = []\n",
    "year_list = []\n",
    "color_list = []\n",
    "for i in range(len(image_name)):\n",
    "    info = image_name[i].split(\"$$\")\n",
    "    brand = info[0]\n",
    "    year = info[2]\n",
    "    color = info[3]\n",
    "    if brand not in brand_list:\n",
    "        brand_list.append(brand)\n",
    "    if year not in year_list:\n",
    "        year_list.append(year)\n",
    "    if color not in color_list:\n",
    "        color_list.append(color)\n",
    "brand_list.sort()\n",
    "year_list.sort()\n",
    "color_list.sort()\n",
    "#Create a dictionary for label,idx\n",
    "brand_dict = {}\n",
    "year_dict = {}\n",
    "color_dict = {}\n",
    "for idx,key in enumerate(brand_list):\n",
    "    brand_dict[key] = idx\n",
    "for idx,key in enumerate(color_list):\n",
    "    color_dict[key] = idx\n",
    "for idx,key in enumerate(year_list):\n",
    "    year_dict[key] = idx\n",
    "# print(len(brand_dict),len(year_dict),len(color_dict))\n",
    "# print(brand_dict)\n",
    "# print(year_dict)\n",
    "# print(color_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary for image,label\n",
    "labels_dict = {}\n",
    "for i in range(len(image_name)):\n",
    "    info = image_name[i].split(\"$$\")\n",
    "    brand = info[0]\n",
    "    year = info[2]\n",
    "    color = info[3]\n",
    "    labels_dict[image_name[i]] = (brand_dict[brand],year_dict[year],color_dict[color])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Some Useful Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(img):\n",
    "    \"\"\" Denormalize input image tensor. (From [0,1] -> [-1,1]) \n",
    "    \n",
    "    Args:\n",
    "        img: input image tensor.\n",
    "    \"\"\"\n",
    "\t\n",
    "    output = img / 2 + 0.5\n",
    "    return output.clamp(0, 1)\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, file_path):\n",
    "    \"\"\" Save model checkpoints. \"\"\"\n",
    "\n",
    "    state = {'model' : model.state_dict(),\n",
    "             'optim' : optimizer.state_dict(),\n",
    "            }\n",
    "    torch.save(state, file_path)\n",
    "    return\n",
    "\n",
    "def load_model(model, optimizer, file_path):\n",
    "    \"\"\" Load previous checkpoints. \"\"\"\n",
    "\n",
    "    prev_state = torch.load(file_path)\n",
    "    \n",
    "    model.load_state_dict(prev_state['model'])\n",
    "    optimizer.load_state_dict(prev_state['optim'])\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, root, labels, class_num, transform):\n",
    "        self.root = root\n",
    "        self.img_folder = os.path.join(self.root, 'confirmed_fronts')\n",
    "        path = os.path.join(self.img_folder,\"Audi\",\"*\",\"*.jpg\") #(folder/brand/year/name)\n",
    "        self.img_files = glob.glob(path)\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.class_num = class_num\n",
    "\n",
    "    def color_transform(self, x):\n",
    "        x = F.adjust_saturation(x, 2.5)\n",
    "        x = F.adjust_gamma(x, 0.7)\n",
    "        x = F.adjust_contrast(x, 1.2)\n",
    "        return x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_files[idx])\n",
    "        img = self.color_transform(img)\n",
    "        img = self.transform(img)\n",
    "        filename = os.path.basename(self.img_files[idx])\n",
    "        label = self.labels[filename]\n",
    "        \n",
    "        one_hots = []\n",
    "        for i, c in enumerate(self.class_num):\n",
    "            #Traversal every class in label (brand,year,color) and change to one hot\n",
    "            # e.g (1,5,10) in class_num = [1,14,18]\n",
    "            # [1,| 0,0,0,0,1,0,0,0,0,0,0,0,0,0, | 0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0] \n",
    "            l = torch.zeros(c)\n",
    "            l[label[i]] = 1\n",
    "            one_hots.append(l)\n",
    "        one_hots = torch.cat(one_hots, 0)\n",
    "        return img, one_hots\n",
    "\n",
    "def image_loader(root, labels, class_num, batch_size):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p = 0.5),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    dataset = Dataset(root, labels, class_num, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True, drop_last = True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, labels):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        self.run_dir = os.path.join('training')\n",
    "        self.data_root = \".\"\n",
    "        \n",
    "        self.lr = 0.0002\n",
    "        self.beta = 0.5\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.classes = {\"brand\":1,\"year\":14,\"color\":18}\n",
    "        self.class_num = tuple([value for key,value in self.classes.items()])\n",
    "        \n",
    "        self.batch_size = 64\n",
    "        self.epochs = 22\n",
    "        self.print_n_iter = 10\n",
    "        self.sample_n_iter = 50 # sample generated image to save to file\n",
    "        self.save_n_epoch = 1\n",
    "        self.itr = 0\n",
    "        \n",
    "        self.dataloader = image_loader(self.data_root,self.labels,self.class_num, self.batch_size)\n",
    "        self.steps_per_epoch = int(np.ceil(self.dataloader.dataset.__len__() * 1.0 / self.batch_size))\n",
    "            \n",
    "        self.input_size = (64,64)\n",
    "        self.noise_dim = 100\n",
    "        self.class_dim = sum(self.class_num)\n",
    "        \n",
    "        self.G = Generator(self.noise_dim, self.class_dim).to(self.device)\n",
    "        self.D = Discriminator(self.class_dim).to(self.device)\n",
    "        \n",
    "        self.dis_crit = nn.BCELoss() # discriminator criterion\n",
    "        self.aux_crit = nn.BCELoss() # classifier criterion\n",
    "        \n",
    "        \n",
    "        self.G_optim = optim.Adam(self.G.parameters(), lr = self.lr, betas = [self.beta, 0.999])\n",
    "        self.D_optim = optim.Adam(self.D.parameters(), lr = self.lr, betas = [self.beta, 0.999])\n",
    "        \n",
    "        self.D_loss_list = []\n",
    "        self.G_loss_list = []\n",
    "        self.cls_loss_list = []\n",
    "        \n",
    "    def generate_class(self, batch_size):\n",
    "        labels = []\n",
    "        \n",
    "        for c in self.class_num:\n",
    "            label = torch.LongTensor(batch_size, 1).random_() % c\n",
    "            one_hot = torch.zeros(batch_size, c).scatter(1, label, 1)\n",
    "            labels.append(one_hot)\n",
    "            \n",
    "        labels = torch.cat(labels, 1)\n",
    "        return labels\n",
    "        \n",
    "    def generate_image(self,sample=10):\n",
    "        for i in range(sample):\n",
    "            z = torch.randn(1, self.noise_dim).to(self.device)\n",
    "            c = self.generate_class(1).to(self.device)\n",
    "            class_img = denorm(self.G(z, c))\n",
    "            os.makedirs(os.path.join('output','Audi'),exist_ok=True)\n",
    "            save_image(class_img, os.path.join('.','output','Audi',f'{i+1}.jpg'))\n",
    "        \n",
    "    def load_model(self, G_file_path, D_file_path, iter):\n",
    "        self.itr = iter\n",
    "        load_model(self.G, self.G_optim, G_file_path)\n",
    "        load_model(self.D, self.D_optim, D_file_path)\n",
    "\n",
    "    def load_log(self):\n",
    "        with open(\"D_loss.pickle\",\"rb\") as f:\n",
    "            self.D_loss_list = pickle.load(f)\n",
    "        with open(\"G_loss.pickle\",\"rb\") as f:\n",
    "            self.G_loss_list = pickle.load(f)\n",
    "        with open(\"class_loss.pickle\",\"rb\") as f:\n",
    "            self.cls_loss_list = pickle.load(f)\n",
    "    \n",
    "    def train_step(self,real_img,real_class):\n",
    "        self.G.train()\n",
    "            \n",
    "        fake_label = torch.zeros(self.batch_size).to(self.device)\n",
    "        \n",
    "        real_img = real_img.to(self.device)\n",
    "        real_class = real_class.to(self.device)\n",
    "        \n",
    "        # Train D\n",
    "        real_label = torch.empty(self.batch_size).uniform_(0.9, 1).to(self.device)\n",
    "        fake_class = self.generate_class(self.batch_size).to(self.device)\n",
    "        z = torch.randn(self.batch_size, self.noise_dim).to(self.device)\n",
    "\n",
    "        fake_img = self.G(z, fake_class).to(self.device)\n",
    "        \n",
    "        real_score, real_pred = self.D(real_img)\n",
    "        fake_score, fake_pred = self.D(fake_img)\n",
    "        \n",
    "        real_dis_loss = self.dis_crit(real_score, real_label)\n",
    "        fake_dis_loss = self.dis_crit(fake_score, fake_label)\n",
    "        dis_loss = (real_dis_loss + fake_dis_loss) * 0.5\n",
    "        \n",
    "        real_aux_loss = self.aux_crit(real_pred, real_class)\n",
    "        \n",
    "        D_loss = real_aux_loss + dis_loss \n",
    "        \n",
    "        self.D_optim.zero_grad()\n",
    "        D_loss.backward()\n",
    "        self.D_optim.step()\n",
    "        \n",
    "        # Train G\n",
    "        real_label = torch.ones(self.batch_size).to(self.device)\n",
    "        fake_class = self.generate_class(self.batch_size).to(self.device)\n",
    "        z = torch.randn(self.batch_size, self.noise_dim).to(self.device)\n",
    "\n",
    "        fake_img = self.G(z, fake_class).to(self.device)\n",
    "        fake_score, fake_pred = self.D(fake_img)\n",
    "        \n",
    "        fake_dis_loss = self.dis_crit(fake_score, real_label)\n",
    "        fake_aux_loss = self.aux_crit(fake_pred, fake_class)\n",
    "        G_loss = fake_aux_loss + fake_dis_loss \n",
    "        \n",
    "        cls_loss = (fake_aux_loss + real_aux_loss) * 0.5\n",
    "        \n",
    "        self.G_optim.zero_grad()\n",
    "        G_loss.backward()\n",
    "        self.G_optim.step()\n",
    "        \n",
    "        return D_loss,G_loss,cls_loss\n",
    "                \n",
    "    def start(self):\n",
    "        \n",
    "        for e in range(self.epochs):\n",
    "            \n",
    "            for i, (real_img, real_class) in enumerate(self.dataloader):\n",
    "                \n",
    "                self.itr += 1\n",
    "                \n",
    "                D_loss, G_loss, cls_loss = self.train_step(real_img,real_class)\n",
    "                \n",
    "                if self.itr % self.print_n_iter == 0 or self.itr == 1 :\n",
    "                    log_text = f\"| Iter {self.itr} | Epoch {e + 1} | {i + 1} / {self.steps_per_epoch} | D_loss: {D_loss.item()} | G_loss: {G_loss.item()} | cls_loss: {cls_loss.item()}\" \n",
    "                    print(log_text)\n",
    "                    self.D_loss_list.append(D_loss.item())\n",
    "                    self.G_loss_list.append(G_loss.item())\n",
    "                    self.cls_loss_list.append(cls_loss.item())\n",
    "                    with open(\"log.txt\",\"a\") as log_file:\n",
    "                        log_file.write(log_text+'\\n')\n",
    "                    \n",
    "                \n",
    "                if self.itr % self.sample_n_iter == 0 or self.itr == 1:\n",
    "                    self.G.eval()\n",
    "                    \n",
    "                    z = torch.randn(self.batch_size, self.noise_dim).to(self.device)\n",
    "                    c = self.generate_class(1).repeat(self.batch_size, 1).to(self.device)\n",
    "                    class_img = denorm(self.G(z, c))\n",
    "                    \n",
    "                    os.makedirs(os.path.join(self.run_dir, 'images'),exist_ok=True)\n",
    "                    save_image(class_img, os.path.join(self.run_dir, 'images', '{}.png'.format(self.itr)))\n",
    "\n",
    "            if (e + 1) % self.save_n_epoch == 0:\n",
    "                os.makedirs( os.path.join(self.run_dir, 'ckpt'),exist_ok=True)\n",
    "                os.makedirs( os.path.join(self.run_dir, 'ckpt'),exist_ok=True)\n",
    "                with open(\"D_loss.pickle\",\"wb\") as f:\n",
    "                    pickle.dump(self.D_loss_list,f)\n",
    "                with open(\"G_loss.pickle\",\"wb\") as f:\n",
    "                    pickle.dump(self.G_loss_list,f)\n",
    "                with open(\"class_loss.pickle\",\"wb\") as f:\n",
    "                    pickle.dump(self.cls_loss_list,f)\n",
    "                save_model(self.G, self.G_optim, os.path.join(self.run_dir, 'ckpt', 'G_{}.pth'.format(self.itr)))\n",
    "                save_model(self.D, self.D_optim, os.path.join(self.run_dir, 'ckpt', 'D_{}.pth'.format(self.itr)))\n",
    "                \n",
    "    def p(self,id):\n",
    "        '''Debuging'''\n",
    "        pass\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(labels_dict)\n",
    "ckpt_dir = os.path.join('training','ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_iter = 3564\n",
    "trainer.load_model(os.path.join(ckpt_dir,f'G_{load_iter}.pth'),os.path.join(ckpt_dir,f'D_{load_iter}.pth'),load_iter)\n",
    "trainer.load_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate image\n",
    "trainer.generate_image()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f45ee7c8811c505473c63122c080a443c5e15828fbf819d8ba83daa4fba756a0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
